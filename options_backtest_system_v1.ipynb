{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca54c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd398e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Options Backtest System Initialized\n",
      "\n",
      "üìã Features:\n",
      "   ‚Ä¢ Multiple file upload (CSV/Excel)\n",
      "   ‚Ä¢ Dynamic DTE-based strategy configuration\n",
      "   ‚Ä¢ Re-entry logic after SL/Profit exits\n",
      "   ‚Ä¢ Carry forward across DTEs until 0 DTE expiry\n",
      "   ‚Ä¢ File-wise and consolidated performance tracking\n",
      "   ‚Ä¢ Excel export with multiple analysis sheets\n",
      "\n",
      "üéØ Instructions:\n",
      "   1. Upload your weekly expiry CSV/Excel files\n",
      "   2. Process files and configure strategy parameters\n",
      "   3. Run backtest to get consolidated results\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd4138802db4044ae7378bd5724c34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%)‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# ============================================================================\n",
    "# GLOBAL STATE MANAGEMENT\n",
    "# ============================================================================\n",
    "\n",
    "class BacktestState:\n",
    "    \"\"\"Centralized state management for the backtest system\"\"\"\n",
    "    def __init__(self):\n",
    "        self.uploaded_files = {}  # {filename: dataframe}\n",
    "        self.processed_data = {}  # {filename: processed_dataframe}\n",
    "        self.strategy_config = None\n",
    "        self.all_results = []\n",
    "        self.results_df = None\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset all state\"\"\"\n",
    "        self.__init__()\n",
    "        \n",
    "    def add_file(self, filename, content):\n",
    "        \"\"\"Add uploaded file\"\"\"\n",
    "        self.uploaded_files[filename] = content\n",
    "        \n",
    "    def get_file_count(self):\n",
    "        \"\"\"Get count of uploaded files\"\"\"\n",
    "        return len(self.uploaded_files)\n",
    "    \n",
    "    def get_filenames(self):\n",
    "        \"\"\"Get list of uploaded filenames\"\"\"\n",
    "        return list(self.uploaded_files.keys())\n",
    "\n",
    "# Initialize global state\n",
    "state = BacktestState()\n",
    "\n",
    "# ============================================================================\n",
    "# DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Enhanced data preprocessing matching your original logic\"\"\"\n",
    "    \n",
    "    # Display settings\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', 100)\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    required_cols = ['expiry_date', 'date_only', 'time', 'symbol', 'open', 'high', 'low', 'close', 'index_close']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Convert date columns\n",
    "    df['expiry_date'] = pd.to_datetime(df['expiry_date']).dt.date\n",
    "    df['date_only'] = pd.to_datetime(df['date_only']).dt.date\n",
    "    \n",
    "    # Calculate days to expiry\n",
    "    df['days_to_expiry'] = (pd.to_datetime(df['expiry_date']) - pd.to_datetime(df['date_only'])).dt.days\n",
    "    \n",
    "    # Filter for weekly options (DTE <= 6)\n",
    "    df = df[df['days_to_expiry'] <= 6].copy()\n",
    "    \n",
    "    # Select required columns\n",
    "    backtest_data = df[['expiry_date', \"date_only\", 'days_to_expiry', 'time', 'symbol', \n",
    "                        'open', 'high', 'low', 'close', 'index_close']].copy()\n",
    "    \n",
    "    # Calculate dte_format dynamically based on unique days_to_expiry values\n",
    "    unique_dte_values = sorted(backtest_data['days_to_expiry'].unique())\n",
    "    dte_mapping = {dte_value: f'{i} DTE' for i, dte_value in enumerate(unique_dte_values)}\n",
    "    backtest_data['dte_format'] = backtest_data['days_to_expiry'].map(dte_mapping)\n",
    "    \n",
    "    return backtest_data\n",
    "\n",
    "# ============================================================================\n",
    "# STRATEGY CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_strategy_config(backtest_data):\n",
    "    \"\"\"Create strategy configuration based on available DTEs\"\"\"\n",
    "    \n",
    "    # Get unique DTEs\n",
    "    unique_dte = sorted(backtest_data['dte_format'].dropna().unique(), reverse=True)\n",
    "    \n",
    "    # Create strategy configuration\n",
    "    strategy_config = pd.DataFrame({\n",
    "        'DTE': unique_dte,\n",
    "        'Stoploss %': [60, 60, 60, 60, 60, 50, 50][:len(unique_dte)],\n",
    "        'Profit Target %': [50, 50, 50, 50, 50, 50, 50][:len(unique_dte)],\n",
    "        'lot_size': [1, 1, 1, 1, 1, 1, 1][:len(unique_dte)],\n",
    "        'PE Strike': [4, 4, 4, 4, 4, 4, 4][:len(unique_dte)],\n",
    "        'CE Strike': [4, 4, 4, 4, 4, 4, 4][:len(unique_dte)],\n",
    "        'Index Movement +/-': [100, 100, 100, 200, 200, 150, 100][:len(unique_dte)]\n",
    "    })\n",
    "    \n",
    "    # Get index_close at 9:15 for each DTE\n",
    "    def get_index_close_at_915(dte):\n",
    "        filtered = backtest_data[\n",
    "            (backtest_data['dte_format'] == dte) &\n",
    "            (backtest_data['time'] == '09:15')\n",
    "        ]\n",
    "        if not filtered.empty:\n",
    "            return filtered['index_close'].iloc[0]\n",
    "        return np.nan\n",
    "    \n",
    "    strategy_config['Index Close'] = strategy_config['DTE'].apply(get_index_close_at_915)\n",
    "    strategy_config['Index Close'] = (strategy_config['Index Close'] / 50).round() * 50\n",
    "    \n",
    "    return strategy_config\n",
    "\n",
    "# ============================================================================\n",
    "# CORE STRATEGY EXECUTION (FROM YOUR ORIGINAL CODE)\n",
    "# ============================================================================\n",
    "\n",
    "def execute_strategy(strategy_row, backtest_data, strategy_config, filename):\n",
    "    \"\"\"\n",
    "    Execute strategy for a given DTE configuration with carry forward and re-entry logic\n",
    "    (Your original logic - preserved exactly)\n",
    "    \"\"\"\n",
    "    \n",
    "    initial_dte = strategy_row['DTE']\n",
    "    \n",
    "    # Track all trades\n",
    "    all_trades = []\n",
    "    \n",
    "    # Get all unique DTEs in descending order\n",
    "    all_dtes = sorted(backtest_data['dte_format'].dropna().unique(), reverse=True)\n",
    "    \n",
    "    # Start from initial DTE\n",
    "    current_dte_index = all_dtes.index(initial_dte)\n",
    "    current_date = None\n",
    "    current_time = None\n",
    "    last_exit_index_close = None\n",
    "    continue_trading = True\n",
    "    trade_number = 1\n",
    "    \n",
    "    # Trading loop\n",
    "    while continue_trading and current_dte_index < len(all_dtes):\n",
    "        \n",
    "        # Get current DTE for entry\n",
    "        entry_dte = all_dtes[current_dte_index]\n",
    "        entry_strategy = strategy_config[strategy_config['DTE'] == entry_dte].iloc[0]\n",
    "        \n",
    "        # Get entry parameters\n",
    "        pe_strike_offset = entry_strategy['PE Strike']\n",
    "        ce_strike_offset = entry_strategy['CE Strike']\n",
    "        lot_size = entry_strategy['lot_size']\n",
    "        \n",
    "        # Determine index close for strike calculation\n",
    "        if last_exit_index_close is not None:\n",
    "            index_close_for_entry = last_exit_index_close\n",
    "        else:\n",
    "            index_close_for_entry = entry_strategy['Index Close']\n",
    "        \n",
    "        # Round to nearest 50\n",
    "        index_close_for_entry = round(index_close_for_entry / 50) * 50\n",
    "        \n",
    "        # Calculate actual strike prices\n",
    "        pe_strike = index_close_for_entry - (pe_strike_offset * 50)\n",
    "        ce_strike = index_close_for_entry + (ce_strike_offset * 50)\n",
    "        \n",
    "        # Create symbol patterns\n",
    "        pe_symbol = f\"{int(pe_strike)}-PE\"\n",
    "        ce_symbol = f\"{int(ce_strike)}-CE\"\n",
    "        \n",
    "        # Filter backtest data for this DTE\n",
    "        dte_data = backtest_data[backtest_data['dte_format'] == entry_dte].copy()\n",
    "        \n",
    "        # Get entry point\n",
    "        if current_date is None and current_time is None:\n",
    "            # First entry at 9:15 AM\n",
    "            pe_entry = dte_data[\n",
    "                (dte_data['symbol'].str.contains(pe_symbol, na=False)) &\n",
    "                (dte_data['time'] == '09:15')\n",
    "            ]\n",
    "            ce_entry = dte_data[\n",
    "                (dte_data['symbol'].str.contains(ce_symbol, na=False)) &\n",
    "                (dte_data['time'] == '09:15')\n",
    "            ]\n",
    "        else:\n",
    "            # Re-entry logic\n",
    "            pe_candidates = dte_data[\n",
    "                (dte_data['symbol'].str.contains(pe_symbol, na=False))\n",
    "            ].copy()\n",
    "            \n",
    "            ce_candidates = dte_data[\n",
    "                (dte_data['symbol'].str.contains(ce_symbol, na=False))\n",
    "            ].copy()\n",
    "            \n",
    "            if pe_candidates.empty or ce_candidates.empty:\n",
    "                current_dte_index += 1\n",
    "                current_date = None\n",
    "                current_time = None\n",
    "                last_exit_index_close = None\n",
    "                continue\n",
    "            \n",
    "            # Create datetime for filtering\n",
    "            pe_candidates['datetime_check'] = pd.to_datetime(\n",
    "                pe_candidates['date_only'].astype(str) + ' ' + pe_candidates['time'].astype(str)\n",
    "            )\n",
    "            ce_candidates['datetime_check'] = pd.to_datetime(\n",
    "                ce_candidates['date_only'].astype(str) + ' ' + ce_candidates['time'].astype(str)\n",
    "            )\n",
    "            \n",
    "            exit_datetime_str = f\"{current_date} {current_time}\"\n",
    "            exit_datetime = pd.to_datetime(exit_datetime_str)\n",
    "            \n",
    "            # Filter for rows AFTER exit time\n",
    "            pe_entry = pe_candidates[pe_candidates['datetime_check'] > exit_datetime].copy()\n",
    "            ce_entry = ce_candidates[ce_candidates['datetime_check'] > exit_datetime].copy()\n",
    "            \n",
    "            if pe_entry.empty or ce_entry.empty:\n",
    "                current_dte_index += 1\n",
    "                current_date = None\n",
    "                current_time = None\n",
    "                last_exit_index_close = None\n",
    "                continue\n",
    "            \n",
    "            pe_entry = pe_entry.iloc[[0]]\n",
    "            ce_entry = ce_entry.iloc[[0]]\n",
    "            \n",
    "            pe_entry = pe_entry.drop(columns=['datetime_check'])\n",
    "            ce_entry = ce_entry.drop(columns=['datetime_check'])\n",
    "        \n",
    "        if pe_entry.empty or ce_entry.empty:\n",
    "            break\n",
    "        \n",
    "        # Get entry prices and details\n",
    "        pe_entry_price = pe_entry.iloc[0]['close']\n",
    "        ce_entry_price = ce_entry.iloc[0]['close']\n",
    "        total_entry_price = pe_entry_price + ce_entry_price\n",
    "        entry_date = pe_entry.iloc[0]['date_only']\n",
    "        entry_time = pe_entry.iloc[0]['time']\n",
    "        entry_index_close = pe_entry.iloc[0]['index_close']\n",
    "        \n",
    "        # Monitor across DTEs until exit\n",
    "        trade_exited = False\n",
    "        \n",
    "        for dte_idx in range(current_dte_index, len(all_dtes)):\n",
    "            current_monitoring_dte = all_dtes[dte_idx]\n",
    "            \n",
    "            # Get strategy parameters for current monitoring DTE\n",
    "            current_strategy = strategy_config[strategy_config['DTE'] == current_monitoring_dte].iloc[0]\n",
    "            current_stoploss_pct = current_strategy['Stoploss %']\n",
    "            current_profit_target_pct = current_strategy['Profit Target %']\n",
    "            current_index_movement = current_strategy['Index Movement +/-']\n",
    "            \n",
    "            # Calculate current targets\n",
    "            stoploss_price = total_entry_price * (1 + current_stoploss_pct/100)\n",
    "            profit_target_price = total_entry_price * (1 - current_profit_target_pct/100)\n",
    "            index_upper_limit = entry_index_close + current_index_movement\n",
    "            index_lower_limit = entry_index_close - current_index_movement\n",
    "            \n",
    "            # Get DTE data\n",
    "            dte_data = backtest_data[backtest_data['dte_format'] == current_monitoring_dte].copy()\n",
    "            \n",
    "            # Filter monitoring data\n",
    "            pe_monitoring = dte_data[\n",
    "                (dte_data['symbol'].str.contains(pe_symbol, na=False))\n",
    "            ].copy()\n",
    "            \n",
    "            ce_monitoring = dte_data[\n",
    "                (dte_data['symbol'].str.contains(ce_symbol, na=False))\n",
    "            ].copy()\n",
    "            \n",
    "            if pe_monitoring.empty or ce_monitoring.empty:\n",
    "                continue\n",
    "            \n",
    "            # Create datetime column for proper time filtering\n",
    "            pe_monitoring['datetime_check'] = pd.to_datetime(\n",
    "                pe_monitoring['date_only'].astype(str) + ' ' + pe_monitoring['time'].astype(str)\n",
    "            )\n",
    "            ce_monitoring['datetime_check'] = pd.to_datetime(\n",
    "                ce_monitoring['date_only'].astype(str) + ' ' + ce_monitoring['time'].astype(str)\n",
    "            )\n",
    "            \n",
    "            # Create entry datetime for filtering\n",
    "            entry_datetime = pd.to_datetime(f\"{entry_date} {entry_time}\")\n",
    "            \n",
    "            # Filter for data >= entry time\n",
    "            pe_monitoring = pe_monitoring[pe_monitoring['datetime_check'] >= entry_datetime].copy()\n",
    "            ce_monitoring = ce_monitoring[ce_monitoring['datetime_check'] >= entry_datetime].copy()\n",
    "            \n",
    "            if pe_monitoring.empty or ce_monitoring.empty:\n",
    "                continue\n",
    "            \n",
    "            # Drop datetime_check before merge\n",
    "            pe_monitoring = pe_monitoring.drop(columns=['datetime_check'])\n",
    "            ce_monitoring = ce_monitoring.drop(columns=['datetime_check'])\n",
    "            \n",
    "            # Merge PE and CE data\n",
    "            monitoring_data = pd.merge(\n",
    "                pe_monitoring[['date_only', 'time', 'close', 'index_close']],\n",
    "                ce_monitoring[['date_only', 'time', 'close']],\n",
    "                on=['date_only', 'time'],\n",
    "                suffixes=('_pe', '_ce')\n",
    "            )\n",
    "            \n",
    "            if monitoring_data.empty:\n",
    "                continue\n",
    "            \n",
    "            # Calculate combined position value\n",
    "            monitoring_data['total_close'] = monitoring_data['close_pe'] + monitoring_data['close_ce']\n",
    "            \n",
    "            # Check for exit conditions\n",
    "            for idx, row in monitoring_data.iterrows():\n",
    "                # Skip entry time point\n",
    "                if row['date_only'] == entry_date and row['time'] == entry_time:\n",
    "                    continue\n",
    "                \n",
    "                # Check if 0 DTE and time is 15:20 (FINAL EXIT)\n",
    "                if current_monitoring_dte == '0 DTE' and row['time'] == '13:20':\n",
    "                    exit_time = row['time']\n",
    "                    exit_date = row['date_only']\n",
    "                    exit_price = row['total_close']\n",
    "                    exit_index_close = row['index_close']\n",
    "                    pnl = (total_entry_price - exit_price) * lot_size * 50\n",
    "                    \n",
    "                    trade_result = {\n",
    "                        'Filename': filename,\n",
    "                        'Trade_Number': trade_number,\n",
    "                        'Entry_DTE': entry_dte,\n",
    "                        'Exit_DTE': current_monitoring_dte,\n",
    "                        'Entry_Date': entry_date,\n",
    "                        'Entry_Time': entry_time,\n",
    "                        'Exit_Date': exit_date,\n",
    "                        'Exit_Time': exit_time,\n",
    "                        'PE_Strike': pe_strike,\n",
    "                        'CE_Strike': ce_strike,\n",
    "                        'PE_Entry_Price': pe_entry_price,\n",
    "                        'CE_Entry_Price': ce_entry_price,\n",
    "                        'Total_Entry_Price': total_entry_price,\n",
    "                        'Exit_Price': exit_price,\n",
    "                        'Exit_Reason': '0 DTE Expiry (3:20 PM)',\n",
    "                        'PnL': pnl,\n",
    "                        'Entry_Index_Close': entry_index_close,\n",
    "                        'Exit_Index_Close': exit_index_close\n",
    "                    }\n",
    "                    \n",
    "                    all_trades.append(trade_result)\n",
    "                    continue_trading = False\n",
    "                    trade_exited = True\n",
    "                    break\n",
    "                \n",
    "                # Check stoploss breach\n",
    "                if row['total_close'] >= stoploss_price:\n",
    "                    exit_time = row['time']\n",
    "                    exit_date = row['date_only']\n",
    "                    exit_price = row['total_close']\n",
    "                    exit_index_close = row['index_close']\n",
    "                    pnl = (total_entry_price - exit_price) * lot_size * 50\n",
    "                    \n",
    "                    trade_result = {\n",
    "                        'Filename': filename,\n",
    "                        'Trade_Number': trade_number,\n",
    "                        'Entry_DTE': entry_dte,\n",
    "                        'Exit_DTE': current_monitoring_dte,\n",
    "                        'Entry_Date': entry_date,\n",
    "                        'Entry_Time': entry_time,\n",
    "                        'Exit_Date': exit_date,\n",
    "                        'Exit_Time': exit_time,\n",
    "                        'PE_Strike': pe_strike,\n",
    "                        'CE_Strike': ce_strike,\n",
    "                        'PE_Entry_Price': pe_entry_price,\n",
    "                        'CE_Entry_Price': ce_entry_price,\n",
    "                        'Total_Entry_Price': total_entry_price,\n",
    "                        'Exit_Price': exit_price,\n",
    "                        'Exit_Reason': 'Stoploss Hit',\n",
    "                        'PnL': pnl,\n",
    "                        'Entry_Index_Close': entry_index_close,\n",
    "                        'Exit_Index_Close': exit_index_close\n",
    "                    }\n",
    "                    \n",
    "                    all_trades.append(trade_result)\n",
    "                    \n",
    "                    current_date = exit_date\n",
    "                    current_time = exit_time\n",
    "                    last_exit_index_close = exit_index_close\n",
    "                    current_dte_index = all_dtes.index(current_monitoring_dte)\n",
    "                    trade_exited = True\n",
    "                    trade_number += 1\n",
    "                    break\n",
    "                \n",
    "                # Check profit target breach\n",
    "                if row['total_close'] <= profit_target_price:\n",
    "                    exit_time = row['time']\n",
    "                    exit_date = row['date_only']\n",
    "                    exit_price = row['total_close']\n",
    "                    exit_index_close = row['index_close']\n",
    "                    pnl = (total_entry_price - exit_price) * lot_size * 50\n",
    "                    \n",
    "                    trade_result = {\n",
    "                        'Filename': filename,\n",
    "                        'Trade_Number': trade_number,\n",
    "                        'Entry_DTE': entry_dte,\n",
    "                        'Exit_DTE': current_monitoring_dte,\n",
    "                        'Entry_Date': entry_date,\n",
    "                        'Entry_Time': entry_time,\n",
    "                        'Exit_Date': exit_date,\n",
    "                        'Exit_Time': exit_time,\n",
    "                        'PE_Strike': pe_strike,\n",
    "                        'CE_Strike': ce_strike,\n",
    "                        'PE_Entry_Price': pe_entry_price,\n",
    "                        'CE_Entry_Price': ce_entry_price,\n",
    "                        'Total_Entry_Price': total_entry_price,\n",
    "                        'Exit_Price': exit_price,\n",
    "                        'Exit_Reason': 'Profit Target Hit',\n",
    "                        'PnL': pnl,\n",
    "                        'Entry_Index_Close': entry_index_close,\n",
    "                        'Exit_Index_Close': exit_index_close\n",
    "                    }\n",
    "                    \n",
    "                    all_trades.append(trade_result)\n",
    "                    \n",
    "                    current_date = exit_date\n",
    "                    current_time = exit_time\n",
    "                    last_exit_index_close = exit_index_close\n",
    "                    current_dte_index = all_dtes.index(current_monitoring_dte)\n",
    "                    trade_exited = True\n",
    "                    trade_number += 1\n",
    "                    break\n",
    "                \n",
    "                # Check index movement breach\n",
    "                if row['index_close'] >= index_upper_limit or row['index_close'] <= index_lower_limit:\n",
    "                    exit_time = row['time']\n",
    "                    exit_date = row['date_only']\n",
    "                    exit_price = row['total_close']\n",
    "                    exit_index_close = row['index_close']\n",
    "                    pnl = (total_entry_price - exit_price) * lot_size * 50\n",
    "                    \n",
    "                    trade_result = {\n",
    "                        'Filename': filename,\n",
    "                        'Trade_Number': trade_number,\n",
    "                        'Entry_DTE': entry_dte,\n",
    "                        'Exit_DTE': current_monitoring_dte,\n",
    "                        'Entry_Date': entry_date,\n",
    "                        'Entry_Time': entry_time,\n",
    "                        'Exit_Date': exit_date,\n",
    "                        'Exit_Time': exit_time,\n",
    "                        'PE_Strike': pe_strike,\n",
    "                        'CE_Strike': ce_strike,\n",
    "                        'PE_Entry_Price': pe_entry_price,\n",
    "                        'CE_Entry_Price': ce_entry_price,\n",
    "                        'Total_Entry_Price': total_entry_price,\n",
    "                        'Exit_Price': exit_price,\n",
    "                        'Exit_Reason': 'Index Movement Breach',\n",
    "                        'PnL': pnl,\n",
    "                        'Entry_Index_Close': entry_index_close,\n",
    "                        'Exit_Index_Close': exit_index_close\n",
    "                    }\n",
    "                    \n",
    "                    all_trades.append(trade_result)\n",
    "                    \n",
    "                    current_date = exit_date\n",
    "                    current_time = exit_time\n",
    "                    last_exit_index_close = exit_index_close\n",
    "                    current_dte_index = all_dtes.index(current_monitoring_dte)\n",
    "                    trade_exited = True\n",
    "                    trade_number += 1\n",
    "                    break\n",
    "            \n",
    "            if trade_exited:\n",
    "                break\n",
    "        \n",
    "        if not trade_exited:\n",
    "            break\n",
    "    \n",
    "    return all_trades\n",
    "\n",
    "# ============================================================================\n",
    "# UI COMPONENTS\n",
    "# ============================================================================\n",
    "\n",
    "def create_file_upload_ui():\n",
    "    \"\"\"Create file upload interface\"\"\"\n",
    "    \n",
    "    upload_widget = widgets.FileUpload(\n",
    "        accept='.csv,.xlsx,.xls',\n",
    "        multiple=True,\n",
    "        description='Upload Files',\n",
    "        button_style='primary',\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    file_list_output = widgets.Output()\n",
    "    upload_status = widgets.HTML()\n",
    "    \n",
    "    def on_upload_change(change):\n",
    "        \"\"\"Handle file upload\"\"\"\n",
    "        with file_list_output:\n",
    "            clear_output()\n",
    "            \n",
    "            uploaded = change['new']\n",
    "            if not uploaded:\n",
    "                return\n",
    "            \n",
    "            # Handle tuple format from FileUpload widget\n",
    "            for file_info in uploaded:\n",
    "                try:\n",
    "                    filename = file_info['name']\n",
    "                    content = file_info['content']\n",
    "                    \n",
    "                    # Read file based on extension\n",
    "                    if filename.endswith('.csv'):\n",
    "                        df = pd.read_csv(io.BytesIO(content))\n",
    "                    elif filename.endswith(('.xlsx', '.xls')):\n",
    "                        df = pd.read_excel(io.BytesIO(content))\n",
    "                    else:\n",
    "                        print(f\"‚ùå Unsupported file format: {filename}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Store in state\n",
    "                    state.add_file(filename, df)\n",
    "                    print(f\"‚úÖ Uploaded: {filename} ({len(df)} rows)\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error uploading {filename}: {str(e)}\")\n",
    "            \n",
    "            # Update status\n",
    "            upload_status.value = f'<p style=\"color: green;\">üìÅ {state.get_file_count()} files uploaded successfully</p>'\n",
    "    \n",
    "    upload_widget.observe(on_upload_change, names='value')\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML('<h3 style=\"color: #2c3e50;\">üìÅ Step 1: Upload Weekly Expiry Files</h3>'),\n",
    "        widgets.HTML('<p style=\"color: #7f8c8d;\">Upload multiple CSV or Excel files containing weekly options data</p>'),\n",
    "        upload_widget,\n",
    "        upload_status,\n",
    "        file_list_output\n",
    "    ])\n",
    "\n",
    "def create_strategy_config_ui():\n",
    "    \"\"\"Create strategy configuration interface\"\"\"\n",
    "    \n",
    "    process_btn = widgets.Button(\n",
    "        description='üîß Process Files & Configure Strategy',\n",
    "        button_style='warning',\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    config_output = widgets.Output()\n",
    "    strategy_widgets = {}\n",
    "    \n",
    "    def on_process_click(b):\n",
    "        \"\"\"Process uploaded files and create strategy config\"\"\"\n",
    "        with config_output:\n",
    "            clear_output()\n",
    "            \n",
    "            if state.get_file_count() == 0:\n",
    "                print(\"‚ùå Please upload files first!\")\n",
    "                return\n",
    "            \n",
    "            print(\"üîß Processing uploaded files...\")\n",
    "            \n",
    "            # Process first file to get DTE structure\n",
    "            first_filename = state.get_filenames()[0]\n",
    "            first_df = state.uploaded_files[first_filename]\n",
    "            \n",
    "            try:\n",
    "                processed = preprocess_data(first_df)\n",
    "                state.processed_data[first_filename] = processed\n",
    "                \n",
    "                # Get unique DTEs\n",
    "                unique_dte = sorted(processed['dte_format'].dropna().unique(), reverse=True)\n",
    "                \n",
    "                print(f\"‚úÖ Detected {len(unique_dte)} DTEs: {unique_dte}\")\n",
    "                print(\"\\n‚öôÔ∏è Configure Strategy Parameters:\\n\")\n",
    "                \n",
    "                # Create configuration widgets\n",
    "                display(HTML('<table style=\"width:100%; border-collapse: collapse;\"><tr style=\"background: #3498db; color: white;\"><th>DTE</th><th>Stoploss %</th><th>Profit Target %</th><th>Lot Size</th><th>PE Offset</th><th>CE Offset</th><th>Index Move</th></tr></table>'))\n",
    "                \n",
    "                for i, dte in enumerate(unique_dte):\n",
    "                    row_widgets = {\n",
    "                        'dte_label': widgets.Label(value=dte, layout=widgets.Layout(width='80px')),\n",
    "                        'sl_pct': widgets.FloatText(value=30 + (i * 5), layout=widgets.Layout(width='100px')),\n",
    "                        'profit_pct': widgets.FloatText(value=50 - (i * 5), layout=widgets.Layout(width='100px')),\n",
    "                        'lot_size': widgets.IntText(value=1, layout=widgets.Layout(width='80px')),\n",
    "                        'pe_strike': widgets.IntText(value=0 if i < 3 else 3, layout=widgets.Layout(width='80px')),\n",
    "                        'ce_strike': widgets.IntText(value=0 if i < 3 else 3, layout=widgets.Layout(width='80px')),\n",
    "                        'index_move': widgets.IntText(value=100, layout=widgets.Layout(width='100px'))\n",
    "                    }\n",
    "                    \n",
    "                    strategy_widgets[dte] = row_widgets\n",
    "                    \n",
    "                    display(widgets.HBox([\n",
    "                        row_widgets['dte_label'],\n",
    "                        row_widgets['sl_pct'],\n",
    "                        row_widgets['profit_pct'],\n",
    "                        row_widgets['lot_size'],\n",
    "                        row_widgets['pe_strike'],\n",
    "                        row_widgets['ce_strike'],\n",
    "                        row_widgets['index_move']\n",
    "                    ]))\n",
    "                \n",
    "                # Store widgets globally\n",
    "                globals()['strategy_widgets'] = strategy_widgets\n",
    "                \n",
    "                print(\"\\n‚úÖ Strategy configuration ready!\")\n",
    "                print(\"üéØ Proceed to execute backtest below\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing files: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    process_btn.on_click(on_process_click)\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML('<h3 style=\"color: #2c3e50;\">‚öôÔ∏è Step 2: Process Files & Configure Strategy</h3>'),\n",
    "        process_btn,\n",
    "        config_output\n",
    "    ])\n",
    "\n",
    "def create_backtest_execution_ui():\n",
    "    \"\"\"Create backtest execution interface\"\"\"\n",
    "    \n",
    "    run_btn = widgets.Button(\n",
    "        description='üöÄ Run Backtest',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(width='200px', height='50px'),\n",
    "        icon='play'\n",
    "    )\n",
    "    \n",
    "    progress_output = widgets.Output()\n",
    "    results_output = widgets.Output()\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        \"\"\"Execute backtest on all files\"\"\"\n",
    "        with progress_output:\n",
    "            clear_output()\n",
    "            \n",
    "            if state.get_file_count() == 0:\n",
    "                print(\"‚ùå Please upload files first!\")\n",
    "                return\n",
    "            \n",
    "            if 'strategy_widgets' not in globals():\n",
    "                print(\"‚ùå Please configure strategy first!\")\n",
    "                return\n",
    "            \n",
    "            print(\"=\"*80)\n",
    "            print(\"üöÄ STARTING MULTI-FILE BACKTEST\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"üìä Total Files: {state.get_file_count()}\\n\")\n",
    "            \n",
    "            all_results = []\n",
    "            \n",
    "            # Process each file\n",
    "            for file_idx, filename in enumerate(state.get_filenames(), 1):\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"üìÇ Processing File {file_idx}/{state.get_file_count()}: {filename}\")\n",
    "                print(f\"{'='*80}\")\n",
    "                \n",
    "                try:\n",
    "                    # Get or process data\n",
    "                    if filename in state.processed_data:\n",
    "                        backtest_data = state.processed_data[filename]\n",
    "                    else:\n",
    "                        df = state.uploaded_files[filename]\n",
    "                        backtest_data = preprocess_data(df)\n",
    "                        state.processed_data[filename] = backtest_data\n",
    "                    \n",
    "                    print(f\"‚úÖ Data loaded: {len(backtest_data)} rows\")\n",
    "                    \n",
    "                    # Create strategy config from widgets\n",
    "                    strategy_config_list = []\n",
    "                    for dte, widgets_dict in strategy_widgets.items():\n",
    "                        strategy_config_list.append({\n",
    "                            'DTE': dte,\n",
    "                            'Stoploss %': widgets_dict['sl_pct'].value,\n",
    "                            'Profit Target %': widgets_dict['profit_pct'].value,\n",
    "                            'lot_size': widgets_dict['lot_size'].value,\n",
    "                            'PE Strike': widgets_dict['pe_strike'].value,\n",
    "                            'CE Strike': widgets_dict['ce_strike'].value,\n",
    "                            'Index Movement +/-': widgets_dict['index_move'].value\n",
    "                        })\n",
    "                    \n",
    "                    strategy_config = pd.DataFrame(strategy_config_list)\n",
    "                    \n",
    "                    # Get index close at 9:15 for each DTE\n",
    "                    def get_index_close_at_915(dte):\n",
    "                        filtered = backtest_data[\n",
    "                            (backtest_data['dte_format'] == dte) &\n",
    "                            (backtest_data['time'] == '09:15')\n",
    "                        ]\n",
    "                        if not filtered.empty:\n",
    "                            return filtered['index_close'].iloc[0]\n",
    "                        return np.nan\n",
    "                    \n",
    "                    strategy_config['Index Close'] = strategy_config['DTE'].apply(get_index_close_at_915)\n",
    "                    strategy_config['Index Close'] = (strategy_config['Index Close'] / 50).round() * 50\n",
    "                    \n",
    "                    print(\"\\nüìã Strategy Config:\")\n",
    "                    print(strategy_config.to_string(index=False))\n",
    "                    \n",
    "                    # Execute strategy\n",
    "                    max_dte_strategy = strategy_config.iloc[0]\n",
    "                    results = execute_strategy(max_dte_strategy, backtest_data, strategy_config, filename)\n",
    "                    \n",
    "                    print(f\"\\n‚úÖ Completed: {len(results)} trades executed\")\n",
    "                    \n",
    "                    all_results.extend(results)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error processing {filename}: {str(e)}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "            \n",
    "            # Display consolidated results\n",
    "            with results_output:\n",
    "                clear_output()\n",
    "                \n",
    "                if all_results:\n",
    "                    results_df = pd.DataFrame(all_results)\n",
    "                    state.results_df = results_df\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*80)\n",
    "                    print(\"üìä BACKTEST COMPLETED - CONSOLIDATED RESULTS\")\n",
    "                    print(\"=\"*80)\n",
    "                    \n",
    "                    # Overall statistics\n",
    "                    total_pnl = results_df['PnL'].sum()\n",
    "                    winning_trades = len(results_df[results_df['PnL'] > 0])\n",
    "                    losing_trades = len(results_df[results_df['PnL'] < 0])\n",
    "                    win_rate = (winning_trades / len(results_df) * 100) if len(results_df) > 0 else 0\n",
    "                    \n",
    "                    print(f\"\\nüéØ OVERALL STATISTICS:\")\n",
    "                    print(f\"{'‚îÄ'*80}\")\n",
    "                    print(f\"Total Files Processed:    {results_df['Filename'].nunique()}\")\n",
    "                    print(f\"Total Trades:             {len(results_df)}\")\n",
    "                    print(f\"Winning Trades:           {winning_trades}\")\n",
    "                    print(f\"Losing Trades:            {losing_trades}\")\n",
    "                    print(f\"Win Rate:                 {win_rate:.2f}%\")\n",
    "                    print(f\"Total P&L:                ‚Çπ{total_pnl:,.2f}\")\n",
    "                    print(f\"Average P&L per Trade:    ‚Çπ{results_df['PnL'].mean():,.2f}\")\n",
    "                    print(f\"Best Trade:               ‚Çπ{results_df['PnL'].max():,.2f}\")\n",
    "                    print(f\"Worst Trade:              ‚Çπ{results_df['PnL'].min():,.2f}\")\n",
    "                    \n",
    "                    # File-wise summary\n",
    "                    print(f\"\\nüìÇ FILE-WISE SUMMARY:\")\n",
    "                    print(f\"{'‚îÄ'*80}\")\n",
    "                    file_summary = results_df.groupby('Filename').agg({\n",
    "                        'PnL': ['sum', 'mean', 'count'],\n",
    "                        'Trade_Number': 'max'\n",
    "                    }).round(2)\n",
    "                    file_summary.columns = ['Total PnL', 'Avg PnL', 'Trades', 'Max Trade #']\n",
    "                    print(file_summary.to_string())\n",
    "                    \n",
    "                    # Exit reason analysis\n",
    "                    print(f\"\\nüéØ EXIT REASON ANALYSIS:\")\n",
    "                    print(f\"{'‚îÄ'*80}\")\n",
    "                    exit_analysis = results_df.groupby('Exit_Reason').agg({\n",
    "                        'PnL': ['sum', 'mean', 'count']\n",
    "                    }).round(2)\n",
    "                    exit_analysis.columns = ['Total PnL', 'Avg PnL', 'Count']\n",
    "                    print(exit_analysis.to_string())\n",
    "                    \n",
    "                    # Export to Excel with comprehensive analysis\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    excel_filename = f'Backtest_Results_{timestamp}.xlsx'\n",
    "                    \n",
    "                    print(f\"\\nüìä Generating comprehensive Excel report...\")\n",
    "                    \n",
    "                    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "                        \n",
    "                        # Sheet 1: All Trades - Complete trade log with week & file source\n",
    "                        all_trades_export = results_df.copy()\n",
    "                        all_trades_export['Week_Number'] = pd.to_datetime(all_trades_export['Entry_Date']).dt.isocalendar().week\n",
    "                        all_trades_export['Month'] = pd.to_datetime(all_trades_export['Entry_Date']).dt.to_period('M').astype(str)\n",
    "                        all_trades_export.to_excel(writer, sheet_name='All_Trades', index=False)\n",
    "                        print(\"   ‚úì Sheet 1: All_Trades\")\n",
    "                        \n",
    "                        # Sheet 2: Strategy Summary - Consolidated strategy performance\n",
    "                        strategy_summary = pd.DataFrame({\n",
    "                            'Metric': [\n",
    "                                'Total Files Processed',\n",
    "                                'Total Trades',\n",
    "                                'Winning Trades',\n",
    "                                'Losing Trades',\n",
    "                                'Win Rate (%)',\n",
    "                                'Total P&L (‚Çπ)',\n",
    "                                'Average P&L per Trade (‚Çπ)',\n",
    "                                'Average Win (‚Çπ)',\n",
    "                                'Average Loss (‚Çπ)',\n",
    "                                'Best Trade (‚Çπ)',\n",
    "                                'Worst Trade (‚Çπ)',\n",
    "                                'Profit Factor',\n",
    "                                'Total Days Traded'\n",
    "                            ],\n",
    "                            'Value': [\n",
    "                                results_df['Filename'].nunique(),\n",
    "                                len(results_df),\n",
    "                                winning_trades,\n",
    "                                losing_trades,\n",
    "                                round(win_rate, 2),\n",
    "                                round(total_pnl, 2),\n",
    "                                round(results_df['PnL'].mean(), 2),\n",
    "                                round(results_df[results_df['PnL'] > 0]['PnL'].mean(), 2) if winning_trades > 0 else 0,\n",
    "                                round(results_df[results_df['PnL'] < 0]['PnL'].mean(), 2) if losing_trades > 0 else 0,\n",
    "                                round(results_df['PnL'].max(), 2),\n",
    "                                round(results_df['PnL'].min(), 2),\n",
    "                                round((results_df[results_df['PnL'] > 0]['PnL'].sum() / abs(results_df[results_df['PnL'] < 0]['PnL'].sum())), 2) if losing_trades > 0 else float('inf'),\n",
    "                                results_df['Entry_Date'].nunique()\n",
    "                            ]\n",
    "                        })\n",
    "                        strategy_summary.to_excel(writer, sheet_name='Strategy_Summary', index=False)\n",
    "                        print(\"   ‚úì Sheet 2: Strategy_Summary\")\n",
    "                        \n",
    "                        # Sheet 3: Overall Metrics - Multi-week KPIs\n",
    "                        overall_metrics = results_df.agg({\n",
    "                            'PnL': ['sum', 'mean', 'std', 'min', 'max', 'count']\n",
    "                        }).round(2)\n",
    "                        overall_metrics_df = pd.DataFrame({\n",
    "                            'Metric': ['Total P&L', 'Average P&L', 'Std Dev P&L', 'Min P&L', 'Max P&L', 'Trade Count'],\n",
    "                            'Value': overall_metrics.values.flatten()\n",
    "                        })\n",
    "                        \n",
    "                        # Add additional KPIs\n",
    "                        sharpe = results_df['PnL'].mean() / results_df['PnL'].std() if results_df['PnL'].std() > 0 else 0\n",
    "                        overall_metrics_df = pd.concat([overall_metrics_df, pd.DataFrame({\n",
    "                            'Metric': ['Sharpe Ratio', 'Total Files', 'Avg Trades per File'],\n",
    "                            'Value': [\n",
    "                                round(sharpe, 2),\n",
    "                                results_df['Filename'].nunique(),\n",
    "                                round(len(results_df) / results_df['Filename'].nunique(), 2)\n",
    "                            ]\n",
    "                        })], ignore_index=True)\n",
    "                        overall_metrics_df.to_excel(writer, sheet_name='Overall_Metrics', index=False)\n",
    "                        print(\"   ‚úì Sheet 3: Overall_Metrics\")\n",
    "                        \n",
    "                        # Sheet 4: DTE Analysis - Performance by DTE with standard deviation\n",
    "                        dte_analysis = results_df.groupby('Entry_DTE').agg({\n",
    "                            'PnL': ['sum', 'mean', 'std', 'count', 'min', 'max']\n",
    "                        }).round(2)\n",
    "                        dte_analysis.columns = ['Total_PnL', 'Avg_PnL', 'Std_Dev', 'Trade_Count', 'Min_PnL', 'Max_PnL']\n",
    "                        dte_analysis['Win_Rate_%'] = results_df.groupby('Entry_DTE').apply(\n",
    "                            lambda x: round((len(x[x['PnL'] > 0]) / len(x) * 100), 2)\n",
    "                        )\n",
    "                        dte_analysis.to_excel(writer, sheet_name='DTE_Analysis')\n",
    "                        print(\"   ‚úì Sheet 4: DTE_Analysis\")\n",
    "                        \n",
    "                        # Sheet 5: Exit Analysis - Exit reason breakdown\n",
    "                        exit_analysis = results_df.groupby('Exit_Reason').agg({\n",
    "                            'PnL': ['sum', 'mean', 'std', 'count', 'min', 'max']\n",
    "                        }).round(2)\n",
    "                        exit_analysis.columns = ['Total_PnL', 'Avg_PnL', 'Std_Dev', 'Count', 'Min_PnL', 'Max_PnL']\n",
    "                        exit_analysis['Win_Rate_%'] = results_df.groupby('Exit_Reason').apply(\n",
    "                            lambda x: round((len(x[x['PnL'] > 0]) / len(x) * 100), 2)\n",
    "                        )\n",
    "                        exit_analysis.to_excel(writer, sheet_name='Exit_Analysis')\n",
    "                        print(\"   ‚úì Sheet 5: Exit_Analysis\")\n",
    "                        \n",
    "                        # Sheet 6: Weekly Performance - Week-by-week results\n",
    "                        results_with_week = results_df.copy()\n",
    "                        results_with_week['Week_Number'] = pd.to_datetime(results_with_week['Entry_Date']).dt.isocalendar().week\n",
    "                        results_with_week['Year'] = pd.to_datetime(results_with_week['Entry_Date']).dt.year\n",
    "                        results_with_week['Week_ID'] = results_with_week['Year'].astype(str) + '-W' + results_with_week['Week_Number'].astype(str).str.zfill(2)\n",
    "                        \n",
    "                        weekly_performance = results_with_week.groupby('Week_ID').agg({\n",
    "                            'PnL': ['sum', 'mean', 'std', 'count', 'min', 'max'],\n",
    "                            'Filename': 'first',\n",
    "                            'Trade_Number': 'max'\n",
    "                        }).round(2)\n",
    "                        weekly_performance.columns = ['Total_PnL', 'Avg_PnL', 'Std_Dev', 'Trades', 'Min_PnL', 'Max_PnL', 'Filename', 'Max_Trade_Num']\n",
    "                        weekly_performance['Win_Rate_%'] = results_with_week.groupby('Week_ID').apply(\n",
    "                            lambda x: round((len(x[x['PnL'] > 0]) / len(x) * 100), 2)\n",
    "                        )\n",
    "                        weekly_performance.to_excel(writer, sheet_name='Weekly_Performance')\n",
    "                        print(\"   ‚úì Sheet 6: Weekly_Performance\")\n",
    "                        \n",
    "                        # Sheet 7: Monthly Performance - Monthly aggregation\n",
    "                        results_with_month = results_df.copy()\n",
    "                        results_with_month['Month'] = pd.to_datetime(results_with_month['Entry_Date']).dt.to_period('M')\n",
    "                        \n",
    "                        monthly_performance = results_with_month.groupby('Month').agg({\n",
    "                            'PnL': ['sum', 'mean', 'std', 'count', 'min', 'max']\n",
    "                        }).round(2)\n",
    "                        monthly_performance.columns = ['Total_PnL', 'Avg_PnL', 'Std_Dev', 'Trades', 'Min_PnL', 'Max_PnL']\n",
    "                        monthly_performance['Win_Rate_%'] = results_with_month.groupby('Month').apply(\n",
    "                            lambda x: round((len(x[x['PnL'] > 0]) / len(x) * 100), 2)\n",
    "                        )\n",
    "                        monthly_performance.index = monthly_performance.index.astype(str)\n",
    "                        monthly_performance.to_excel(writer, sheet_name='Monthly_Performance')\n",
    "                        print(\"   ‚úì Sheet 7: Monthly_Performance\")\n",
    "                        \n",
    "                        # Sheet 8: Cumulative P&L - With week tracking\n",
    "                        cumulative_data = results_df.sort_values(['Filename', 'Entry_Date', 'Entry_Time']).copy()\n",
    "                        cumulative_data['Cumulative_PnL'] = cumulative_data['PnL'].cumsum()\n",
    "                        cumulative_data['Week_Number'] = pd.to_datetime(cumulative_data['Entry_Date']).dt.isocalendar().week\n",
    "                        cumulative_data['Year'] = pd.to_datetime(cumulative_data['Entry_Date']).dt.year\n",
    "                        cumulative_data['Week_ID'] = cumulative_data['Year'].astype(str) + '-W' + cumulative_data['Week_Number'].astype(str).str.zfill(2)\n",
    "                        \n",
    "                        cumulative_export = cumulative_data[[\n",
    "                            'Filename', 'Week_ID', 'Entry_Date', 'Entry_Time', \n",
    "                            'Trade_Number', 'PnL', 'Cumulative_PnL', 'Exit_Reason'\n",
    "                        ]].copy()\n",
    "                        cumulative_export.to_excel(writer, sheet_name='Cumulative_PnL', index=False)\n",
    "                        print(\"   ‚úì Sheet 8: Cumulative_PnL\")\n",
    "                        \n",
    "                        # Sheet 9: Drawdown Analysis - With week context\n",
    "                        cumulative_sorted = results_df.sort_values(['Filename', 'Entry_Date', 'Entry_Time']).copy()\n",
    "                        cumulative_sorted['Cumulative_PnL'] = cumulative_sorted['PnL'].cumsum()\n",
    "                        cumulative_sorted['Running_Max'] = cumulative_sorted['Cumulative_PnL'].cummax()\n",
    "                        cumulative_sorted['Drawdown'] = cumulative_sorted['Cumulative_PnL'] - cumulative_sorted['Running_Max']\n",
    "                        cumulative_sorted['Drawdown_%'] = (cumulative_sorted['Drawdown'] / cumulative_sorted['Running_Max'].abs()) * 100\n",
    "                        cumulative_sorted['Drawdown_%'] = cumulative_sorted['Drawdown_%'].fillna(0)\n",
    "                        \n",
    "                        cumulative_sorted['Week_Number'] = pd.to_datetime(cumulative_sorted['Entry_Date']).dt.isocalendar().week\n",
    "                        cumulative_sorted['Year'] = pd.to_datetime(cumulative_sorted['Entry_Date']).dt.year\n",
    "                        cumulative_sorted['Week_ID'] = cumulative_sorted['Year'].astype(str) + '-W' + cumulative_sorted['Week_Number'].astype(str).str.zfill(2)\n",
    "                        \n",
    "                        drawdown_export = cumulative_sorted[[\n",
    "                            'Filename', 'Week_ID', 'Entry_Date', 'Trade_Number',\n",
    "                            'PnL', 'Cumulative_PnL', 'Running_Max', 'Drawdown', 'Drawdown_%'\n",
    "                        ]].copy()\n",
    "                        drawdown_export.to_excel(writer, sheet_name='Drawdown_Analysis', index=False)\n",
    "                        print(\"   ‚úì Sheet 9: Drawdown_Analysis\")\n",
    "                        \n",
    "                        # Add summary statistics for drawdown\n",
    "                        max_drawdown = cumulative_sorted['Drawdown'].min()\n",
    "                        max_drawdown_pct = cumulative_sorted['Drawdown_%'].min()\n",
    "                        max_dd_date = cumulative_sorted.loc[cumulative_sorted['Drawdown'].idxmin(), 'Entry_Date']\n",
    "                        max_dd_week = cumulative_sorted.loc[cumulative_sorted['Drawdown'].idxmin(), 'Week_ID']\n",
    "                        \n",
    "                        drawdown_summary = pd.DataFrame({\n",
    "                            'Metric': [\n",
    "                                'Max Drawdown (‚Çπ)',\n",
    "                                'Max Drawdown (%)',\n",
    "                                'Max DD Date',\n",
    "                                'Max DD Week',\n",
    "                                'Recovery Trades',\n",
    "                                'Avg Drawdown (‚Çπ)',\n",
    "                                'Drawdown Days'\n",
    "                            ],\n",
    "                            'Value': [\n",
    "                                round(max_drawdown, 2),\n",
    "                                round(max_drawdown_pct, 2),\n",
    "                                str(max_dd_date),\n",
    "                                max_dd_week,\n",
    "                                len(cumulative_sorted[cumulative_sorted['Drawdown'] < 0]),\n",
    "                                round(cumulative_sorted[cumulative_sorted['Drawdown'] < 0]['Drawdown'].mean(), 2),\n",
    "                                cumulative_sorted[cumulative_sorted['Drawdown'] < 0]['Entry_Date'].nunique()\n",
    "                            ]\n",
    "                        })\n",
    "                        \n",
    "                        # Append drawdown summary to the same sheet\n",
    "                        startrow = len(drawdown_export) + 3\n",
    "                        drawdown_summary.to_excel(writer, sheet_name='Drawdown_Analysis', \n",
    "                                                  startrow=startrow, index=False)\n",
    "                    \n",
    "                    print(f\"\\n‚úÖ Comprehensive Excel report generated: {excel_filename}\")\n",
    "                    print(f\"üìä Total sheets: 9\")\n",
    "                    print(\"\\nüíæ Results stored in 'state.results_df' for further analysis\")\n",
    "                    \n",
    "                else:\n",
    "                    print(\"\\n‚ùå No trades executed across all files\")\n",
    "    \n",
    "    run_btn.on_click(on_run_click)\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML('<h3 style=\"color: #2c3e50;\">üöÄ Step 3: Execute Backtest</h3>'),\n",
    "        run_btn,\n",
    "        progress_output,\n",
    "        results_output\n",
    "    ])\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN UI ASSEMBLY\n",
    "# ============================================================================\n",
    "\n",
    "def create_main_ui():\n",
    "    \"\"\"Assemble main user interface\"\"\"\n",
    "    \n",
    "    header = widgets.HTML('''\n",
    "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                    padding: 30px; \n",
    "                    border-radius: 10px; \n",
    "                    text-align: center;\n",
    "                    margin-bottom: 20px;\">\n",
    "            <h1 style=\"color: white; margin: 0; font-size: 36px;\">üìà Options Backtest System</h1>\n",
    "            <p style=\"color: #e0e0e0; margin: 10px 0 0 0; font-size: 18px;\">\n",
    "                Multi-File Strategy Backtesting with Re-Entry Logic\n",
    "            </p>\n",
    "        </div>\n",
    "    ''')\n",
    "    \n",
    "    divider = widgets.HTML('<hr style=\"border: 2px solid #3498db; margin: 30px 0;\">')\n",
    "    \n",
    "    file_upload_ui = create_file_upload_ui()\n",
    "    strategy_config_ui = create_strategy_config_ui()\n",
    "    backtest_execution_ui = create_backtest_execution_ui()\n",
    "    \n",
    "    main_ui = widgets.VBox([\n",
    "        header,\n",
    "        file_upload_ui,\n",
    "        divider,\n",
    "        strategy_config_ui,\n",
    "        divider,\n",
    "        backtest_execution_ui\n",
    "    ])\n",
    "    \n",
    "    return main_ui\n",
    "\n",
    "# ============================================================================\n",
    "# LAUNCH APPLICATION\n",
    "# ============================================================================\n",
    "\n",
    "def launch_backtest_system():\n",
    "    \"\"\"Launch the backtest system\"\"\"\n",
    "    \n",
    "    print(\"‚úÖ Options Backtest System Initialized\")\n",
    "    print(\"\\nüìã Features:\")\n",
    "    print(\"   ‚Ä¢ Multiple file upload (CSV/Excel)\")\n",
    "    print(\"   ‚Ä¢ Dynamic DTE-based strategy configuration\")\n",
    "    print(\"   ‚Ä¢ Re-entry logic after SL/Profit exits\")\n",
    "    print(\"   ‚Ä¢ Carry forward across DTEs until 0 DTE expiry\")\n",
    "    print(\"   ‚Ä¢ File-wise and consolidated performance tracking\")\n",
    "    print(\"   ‚Ä¢ Excel export with multiple analysis sheets\")\n",
    "    print(\"\\nüéØ Instructions:\")\n",
    "    print(\"   1. Upload your weekly expiry CSV/Excel files\")\n",
    "    print(\"   2. Process files and configure strategy parameters\")\n",
    "    print(\"   3. Run backtest to get consolidated results\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    main_ui = create_main_ui()\n",
    "    display(main_ui)\n",
    "\n",
    "# Auto-launch when imported\n",
    "if __name__ == '__main__':\n",
    "    launch_backtest_system()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
